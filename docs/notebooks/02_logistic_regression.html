
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Logistic Regression &#8212; Credit Card Fraud Detection</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/02_logistic_regression';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Gradient boosted-tree using XGBoost" href="03_XGB.html" />
    <link rel="prev" title="Exploratory Data Analysis" href="01_eda.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Credit Card Fraud Detection</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_eda.html">Exploratory Data Analysis</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_XGB.html">Gradient boosted-tree using XGBoost</a></li>
<li class="toctree-l1"><a class="reference internal" href="API.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="conclusion.html">Conclusion</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/02_logistic_regression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Logistic Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-splits">Time Splits</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-evaluation">Model Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calibration">Calibration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limits">Limits</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#threshold-selection">Threshold selection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression-conclusion">Logistic Regression — Conclusion</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="logistic-regression">
<h1>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Link to this heading">#</a></h1>
<p>Logistic Regression is a simple yet effective model, and makes for a good baseline. We will use it to introduce the metrics and techniques used to deal with high class imbalance, and to check whether using a more sophisticated model (gradient boosted tree) later improves performance.</p>
<section id="time-splits">
<h2>Time Splits<a class="headerlink" href="#time-splits" title="Link to this heading">#</a></h2>
<p>When dealing with a time series, data needs to be split across time to preserve causality and avoid information leakage. A single compromised payment method will generate several fraudulent transactions. If those transactions find themselves both in the test and training datasets, performance will increase artificially and the model will not generalize well.</p>
<p>Let demonstrate the trap of information leakage by training the model using two different time splits:<br />
-First one trains on 0-50% of the data and calibrates+tests on 70-100%<br />
-Second one trains on 20-70% of the data and calibrates+tests on 70-100%</p>
<p>Though the training sample size is roughly the same, and test/calibration sets are identical, the 20-70 split performs substantially better as can be seen on the ROC and PR plots (see the Model Evaluation section). This advantage is misleading: as data from the second day can be found both in training and testing sets, the model leverages data leakage to make better predictions, but this improvement would on data that is truly new.</p>
<p>This nicely demonstrates the necessity for a time buffer between training and testing data to avoid overly optimistic performance estimates. In our case, with two days of data we can only go so far, so we will stick with split 1 (training only day 1) for the remainder of this project.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Data and libraries imports</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.calibration</span><span class="w"> </span><span class="kn">import</span> <span class="n">CalibratedClassifierCV</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">RocCurveDisplay</span><span class="p">,</span> <span class="n">PrecisionRecallDisplay</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.patches</span><span class="w"> </span><span class="kn">import</span> <span class="n">Rectangle</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">plotly.graph_objects</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">go</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">plotly.io</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pio</span>
<span class="c1">#pio.renderers.default = &quot;plotly-mimetype&quot;</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.calibration</span><span class="w"> </span><span class="kn">import</span> <span class="n">calibration_curve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot_cost_function</span><span class="p">,</span> <span class="n">classify</span><span class="p">,</span> <span class="n">compute_TPR</span><span class="p">,</span> <span class="n">compute_precision</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/raw.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Time split</span>

<span class="n">maxTime</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

<span class="n">df_train_1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">between</span><span class="p">(</span><span class="mi">0</span> <span class="o">*</span> <span class="n">maxTime</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">maxTime</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)]</span>
<span class="n">df_train_2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">between</span><span class="p">(</span><span class="mf">0.2</span> <span class="o">*</span> <span class="n">maxTime</span><span class="p">,</span> <span class="mf">0.7</span> <span class="o">*</span> <span class="n">maxTime</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)]</span>
<span class="n">df_cal</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">between</span><span class="p">(</span><span class="mf">0.7</span> <span class="o">*</span> <span class="n">maxTime</span><span class="p">,</span> <span class="mf">0.85</span> <span class="o">*</span> <span class="n">maxTime</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)]</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.85</span> <span class="o">*</span> <span class="n">maxTime</span><span class="p">]</span>

<span class="n">X_train_1</span> <span class="o">=</span> <span class="n">df_train_1</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">,</span> <span class="s2">&quot;Amount&quot;</span><span class="p">])</span>
<span class="n">X_train_2</span> <span class="o">=</span> <span class="n">df_train_2</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">,</span> <span class="s2">&quot;Amount&quot;</span><span class="p">])</span>
<span class="n">X_cal</span> <span class="o">=</span> <span class="n">df_cal</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">,</span> <span class="s2">&quot;Amount&quot;</span><span class="p">])</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">,</span> <span class="s2">&quot;Amount&quot;</span><span class="p">])</span>

<span class="n">Y_train_1</span> <span class="o">=</span> <span class="n">df_train_1</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>
<span class="n">Y_train_2</span> <span class="o">=</span> <span class="n">df_train_2</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>
<span class="n">Y_cal</span> <span class="o">=</span> <span class="n">df_cal</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>

<span class="c1">## Models</span>

<span class="n">model_1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_1</span><span class="p">,</span> <span class="n">Y_train_1</span><span class="p">)</span>

<span class="n">model_2</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_2</span><span class="p">,</span> <span class="n">Y_train_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-7 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-7 {
  color: var(--sklearn-color-text);
}

#sk-container-id-7 pre {
  padding: 0;
}

#sk-container-id-7 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-7 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-7 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-7 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-7 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-7 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-7 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-7 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-7 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-7 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-7 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-7 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-7 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-7 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-7 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-7 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-7 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-7 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-7 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-7 div.sk-label label.sk-toggleable__label,
#sk-container-id-7 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-7 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-7 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-7 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-7 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-7 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-7 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-7 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-7 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-7 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-7 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-7" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" checked><label for="sk-estimator-id-7" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>LogisticRegression</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, n_jobs=-1)</pre></div> </div></div></div></div></div></div>
</div>
</section>
<section id="model-evaluation">
<h2>Model Evaluation<a class="headerlink" href="#model-evaluation" title="Link to this heading">#</a></h2>
<p>For problems with high class imbalance such as this one, accuracy alone is not apropriate. A simple classifier that flags all transactions as genuine would have an accuracy of 100 - 0.17 = 99.83%, but would be completely useless. A useful fraud detection model must achieve both a high recall (the proportion of positives correctly classified, also known as the True Positive Rate) <strong>and</strong> a high precision (the proportion of predicted positives that are actual positives).</p>
<p>Precision and recall depend on the decision threshold. A model that outputs probability estimates typically applies a default threshold of 0.5. For highly imbalanced data however, the threshold needs to be chosen carefully (see the Threshold Selection section), as the low number of positives makes the trade-off between recall and precision critical.</p>
<p>We can obtain threshold-independent metrics by plotting simple metrics for all threshold values:</p>
<ul class="simple">
<li><p>The Receiver Operating Characteristic plots the True Positive Rate (or recall) against the False Positive Rate for all thresholds. A perfect classifier would achieve a TPR of 1 and a FPR of 0 for some threshold value, meaning the curve would go from (0,0) to (0,1) to then (1,1). For a random classifier, the probability for any sample to be classified as positive is equal to 1 - threshold, and so are both the TPR and the FPR. The curve would go from (0,0) to (1,1). For a real model, we can expect anything in between, but the closer we get to the perfect classifier the better.</p></li>
<li><p>The Precision-Recall curve plots the precision agaisnt the recall for all thresholds. A perfect classifier would achieve a precision of 1 and a recall of 1 for some threshold, so it would go from (0,1) to (1,1) to then (1,0). A random classifier would always have a precision equal to the prevalence rate, 0.0017 in our case, so the curve would go from (0, 0.0017) to (1, 0.0017). For a real model, we can expect anything in between, but the closer we get to the perfect classifier the better.</p></li>
</ul>
<p>Looking at the PR and ROC for our logistic regression models, we can note two things:</p>
<ul class="simple">
<li><p>The model trained on the second time split performs a little better.</p></li>
<li><p>Both models demonstrate suspsiciously good performances overall. A sophisticated model trained on extensive data with well made feature engineering can expect to reach an AUC ROC of 0.9 and a AUC PR of 0.5. An AUC of .94 and of .70 for the ROC and PR curves respectively would rank our fraud detection model among the very best, but we should rather interpret those metrics as indication of our dataset’s limitations. Indeed, fraud patterns are probably really similar across the two-days, and the model learns to recognize those specific patterns instead of what fraud might look like in general. For example, a card that was already seen as compromised on the training data and that made further fraudulent transactions on the testing data would artificially increase the performances.</p></li>
</ul>
<p>In any case, the metrics obtained for the logistic regression can serve as comparison for the gradient boosted tree we will train in the next chapter.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Model evaluation: ROC and PR</span>


<span class="n">Y_proba_1</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Y_proba_2</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Receiver Operating Characteristic&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Precision Recall Curve&quot;</span><span class="p">)</span>

<span class="n">RocCurveDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Split 1 (0-50%)&quot;</span><span class="p">,</span>
    <span class="n">plot_chance_level</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">PrecisionRecallDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Split 1 (0-50%)&quot;</span><span class="p">,</span>
    <span class="n">plot_chance_level</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">RocCurveDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Split 2 (20-70%)&quot;</span>
<span class="p">)</span>

<span class="n">PrecisionRecallDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Split 2 (20-70%)&quot;</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/0033970cdeff0cb221f8ec10261909ed5a17717398e3e1821e2cceca404c1d44.png" src="../_images/0033970cdeff0cb221f8ec10261909ed5a17717398e3e1821e2cceca404c1d44.png" />
</div>
</div>
<div align="center">
<p><strong>Figure - Receiver Operating Characteristic and Precision Recall for the two considered time splits</strong></p>
<p>When training and testing datasets are separeted by a time buffer (split 1), the performances are worse. This illustrates the dangers of information leakage.</p>
</div></section>
<section id="calibration">
<h2>Calibration<a class="headerlink" href="#calibration" title="Link to this heading">#</a></h2>
<section id="motivation">
<h3>Motivation<a class="headerlink" href="#motivation" title="Link to this heading">#</a></h3>
<p>In principle, a probabilistic classifier outputs estimated class probabilities. For instance, among all transactions assigned a score of around 0.6, roughly 60% should indeed be fraudulent. When that relationship holds for all probabilities a model is said to be well-calibrated.</p>
<p>In practice, this property often breaks down when models are trained on highly imbalanced data, especially when class weighting is used. In such cases, the models tend to become overconfident: most fraudulent transactions receive very high scores, while most genuine transactions receive very low scores, with comparatively fewer samples in between.</p>
<p>We can see this phenomenon on the recall/threshold curve (see the Threshold Selection section). Even for thresholds as high as 0.995, the majority of positives are already identified.<br />
This doesn’t mean the model performs poorly, but a well-calibrated model makes dynamically choosing a threshold easier, for two reasons:</p>
<ol class="arabic simple">
<li><p>The output probabilities are easily interpretable (around 0.6, the model is 60% confident).</p></li>
<li><p>The changes of recall/precision with threshold are more gradual.</p></li>
</ol>
<p>For these reasons, we map the output values of the model from raw scores to calibrated probabilities, typically using Platt-scaling or an isotonic regression. Calibration changes the outputs of the model but keeps the order of the predictions, as the function we fit at the output is a monotonically increasing function. This means that performances that rely on the order of the predictions but not on the exact values (PR and ROC curves as well as Recall/Precision&#64;K) are not altered, as we can see on the following plots (the curves overlap for the calibrated/uncalibrated models).</p>
</section>
<section id="limits">
<h3>Limits<a class="headerlink" href="#limits" title="Link to this heading">#</a></h3>
<p>The calibration step tries its best to make the probability estimates accurate without tampering with the order. Because rankings are preserved, calibration can only correct probability estimates to a limited extent when the underlying model already separates positives and negatives extremely well.</p>
<p>Those limits can be seen on the calibration curve we plotted for the test data. The curve is obtained by binning predictions by score and plotting, for each bin, the empirical fraction of positive samples against the predicted probability.<br />
For the uncalibrated model, only the last bin contains a significant portion of positives.</p>
<p>After calibration, the model attempts to align predicted probabilities with empirical frequencies, but two constraints remain:</p>
<ol class="arabic simple">
<li><p>Data scarcity: the dataset contains fewer than 500 fraud cases in total, and only around 70 in the calibration set, leading to high variance in probability estimates.</p></li>
<li><p>Preserved ordering: because ranking is unchanged, predictions above a threshold of roughly 0.3 are still overwhelmingly positive. The model calibrator cannot do any better without tempering the order, which we don’t want.</p></li>
</ol>
<p>This is a nice reminder that calibration is a tool, not an end: a hypothetical perfect model that ascribes 1 to all frauds and 0 to all non-frauds would be insensitive to calibration.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_platt</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span>
    <span class="n">model_1</span><span class="p">,</span> 
    <span class="n">method</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span>  <span class="c1"># platt-sclaing: fitting a sigmoïd on top of the model</span>
    <span class="n">cv</span><span class="o">=</span><span class="s1">&#39;prefit&#39;</span>
<span class="p">)</span>

<span class="n">model_iso</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span>
    <span class="n">model_1</span><span class="p">,</span> 
    <span class="n">method</span><span class="o">=</span><span class="s1">&#39;isotonic&#39;</span><span class="p">,</span>  <span class="c1"># isotonic regression: fitting a constant-by-step function instead of a sigmoid</span>
    <span class="n">cv</span><span class="o">=</span><span class="s1">&#39;prefit&#39;</span>
<span class="p">)</span>

<span class="n">model_platt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_cal</span><span class="p">,</span> <span class="n">Y_cal</span><span class="p">)</span>
<span class="n">model_iso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_cal</span><span class="p">,</span> <span class="n">Y_cal</span><span class="p">)</span>

<span class="n">Y_proba_1</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Y_proba_platt</span> <span class="o">=</span> <span class="n">model_platt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Y_proba_iso</span> <span class="o">=</span> <span class="n">model_platt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">RocCurveDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Uncalibrated&quot;</span><span class="p">,</span>
    <span class="n">plot_chance_level</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">PrecisionRecallDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Uncalibrated&quot;</span><span class="p">,</span>
    <span class="n">plot_chance_level</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">RocCurveDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_platt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Platt-scaling&quot;</span>
<span class="p">)</span>

<span class="n">PrecisionRecallDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_platt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Platt-scaling&quot;</span>
<span class="p">)</span>

<span class="n">RocCurveDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_iso</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;isotonic regression&quot;</span>
<span class="p">)</span>

<span class="n">PrecisionRecallDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_iso</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;isotonic regression&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/10b7cb4d66c693df111781945510721149a59f44f1142e8f327609e07069dcb3.png" src="../_images/10b7cb4d66c693df111781945510721149a59f44f1142e8f327609e07069dcb3.png" />
</div>
</div>
<div align="center">
<p><strong>Figure - Receiver Operating Characteristic and Precision Recall for the uncalibrated and calibrated models</strong></p>
<p>Performances are the same for the uncalibrated and calibrated models, as the calibration doesn’t change the ranking of the outputs.</p>
</div><div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Calibration curve</span>

<span class="n">Y_proba_1</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Y_proba_platt</span> <span class="o">=</span> <span class="n">model_platt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Y_proba_iso</span> <span class="o">=</span> <span class="n">model_iso</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">prob_true</span><span class="p">,</span> <span class="n">prob_pred</span> <span class="o">=</span> <span class="n">calibration_curve</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span>
<span class="p">)</span>

<span class="n">prob_true_platt</span><span class="p">,</span> <span class="n">prob_pred_platt</span> <span class="o">=</span> <span class="n">calibration_curve</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_platt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">n_bins</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span>
<span class="p">)</span>

<span class="n">prob_true_iso</span><span class="p">,</span> <span class="n">prob_pred_iso</span> <span class="o">=</span> <span class="n">calibration_curve</span><span class="p">(</span>
    <span class="n">Y_test</span><span class="p">,</span>
    <span class="n">Y_proba_iso</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">n_bins</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">prob_pred</span><span class="p">,</span> <span class="n">prob_true</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;uncalibrated&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">prob_pred_platt</span><span class="p">,</span> <span class="n">prob_true_platt</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;platt-calibrated&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">prob_pred_iso</span><span class="p">,</span> <span class="n">prob_true_iso</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;iso-calibrated&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted probability&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Observed fraud rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Calibration Curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/3d0f912cf0a96db34da1f33df4c68b1002a7e13bbc1f09f76026a739befacba1.png" src="../_images/3d0f912cf0a96db34da1f33df4c68b1002a7e13bbc1f09f76026a739befacba1.png" />
</div>
</div>
<div align="center">
<p><strong>Figure - Calibration curve for the uncalibrated and calibrated models</strong></p>
<p>Calibration can only be approximate because of low samples and very well separated data.</p>
</div></section>
</section>
<section id="threshold-selection">
<h2>Threshold selection<a class="headerlink" href="#threshold-selection" title="Link to this heading">#</a></h2>
<p>As mentioned before, for data with high imbalance, keeping the default 0.5 threshold is rarely appropriate. In fraud detection, achieving a high recall generally requires accepting a substantial number of false positives, as fraudulent transactions do not all stand out clearly from genuine ones.
There are several strategies we can rely on to choose the threshold, most notably:</p>
<ul class="simple">
<li><p>Minimum recall approach: “We owe our clients to catch at least X% of the frauds”. This strategy is limited, as it doesn’t take into account the cost of a low precision.</p></li>
<li><p>Cost function approach: “A false negative costs X, a false positive costs Y, what threshold minimizes the overall cost ?”. This is a very reliable approach, granted you are able to estimate those costs correctly. This can be tricky, as the cost of mistakes includes a reputational cost on top of a monetary one.</p></li>
<li><p>Top K selection approach: if N agents can each go through M transactions during the day, then pick the K = M * N most suspicious transactions for verification.</p></li>
</ul>
<p>Each of these strategies emphasizes a different operational constraint, and they may all come in handy in different settings.</p>
<p>To keep things simple, we adopt a cost-based approach with the following cost function for our threshold choice:</p>
<div class="math notranslate nohighlight">
\[C=20⋅FN+1⋅FP\]</div>
<p>This reflects the assumption that missing a fraudulent transaction is approximately twenty times more costly than raising a false alert. While this ratio is admittedly arbitrary —it could reasonably be set to 50 or even 100— the resulting optimal threshold is relatively stable.</p>
<p>As you can see on the precision and recall plots below, there is a threshold below which the recall plateaus while the precision drops. To check wether the decision threshold depends strongly on the cost function used, let us plot of the cost function for different values of the relative cost between False Negatives and False Positives: 20, 50, 100. As you can see, the optimal threshold is right at the tipping point for all three cases.</p>
<p>This robustness suggests that, despite the uncertainty in cost estimation, the chosen threshold captures a sensible trade-off between fraud detection effectiveness and operational burden.</p>
<p>We can now confidently say that a threshold  around 0.01 for our model is optimal, and compute the corresponding performances on the test set: TPR = 77%, Precision = 50%.</p>
<p>Again, those results are abnormally good because of the limited time span of the data set and its exceptional quality.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Precision and Recall against threshold, w/wo calibration</span>

<span class="n">Y_proba</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Y_proba_platt</span> <span class="o">=</span> <span class="n">model_platt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_proba</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="c1">## First column of Y_proba are probabilities for Class=0, second col Class=1</span>
<span class="n">precision_cal</span><span class="p">,</span> <span class="n">recall_cal</span><span class="p">,</span> <span class="n">thresholds_cal</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_proba_platt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="c1">## First column of Y_proba are probabilities for Class=0, second col Class=1</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">thresholds</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">precision</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Precision&quot;</span><span class="p">,</span>
<span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">thresholds</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">recall</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Recall&quot;</span><span class="p">,</span>
<span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Precision &amp; Recall vs Threshold, no calibration&quot;</span><span class="p">,</span>
    <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;Threshold&quot;</span><span class="p">,</span>
    <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;Score&quot;</span><span class="p">,</span>
    <span class="n">hovermode</span><span class="o">=</span><span class="s2">&quot;x unified&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">thresholds_cal</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">precision_cal</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Precision&quot;</span><span class="p">,</span>
<span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">thresholds_cal</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">recall_cal</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Recall&quot;</span><span class="p">,</span>
<span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Precision &amp; Recall vs Threshold,  with Platt scaling calibration&quot;</span><span class="p">,</span>
    <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;Threshold&quot;</span><span class="p">,</span>
    <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;Score&quot;</span><span class="p">,</span>
    <span class="n">hovermode</span><span class="o">=</span><span class="s2">&quot;x unified&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
</div>
</div>
<div align="center">
<p><strong>Figure - Precision and Recall against threshold for uncalibrated and Platt-scaled models</strong></p>
<p>This plot makes the trade-off between recall and precision very obvious. For the uncalibrated model, you can see the recall plateau around 0.8 while the precision drops drastically.</p>
</div><div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_proba_platt</span> <span class="o">=</span> <span class="n">model_platt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">cost_function</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimal thresholds:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">relative_cost</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="n">thresholds</span><span class="p">,</span> <span class="n">costs</span> <span class="o">=</span> <span class="n">plot_cost_function</span><span class="p">(</span><span class="n">relative_cost</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">to_list</span><span class="p">(),</span> <span class="n">Y_proba_platt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">thresholds</span><span class="p">,</span> <span class="n">costs</span> <span class="o">=</span> <span class="n">plot_cost_function</span><span class="p">(</span><span class="n">relative_cost</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">to_list</span><span class="p">(),</span> <span class="n">Y_proba_platt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Cost against threshold (zoom)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;relative cost = &quot;</span><span class="p">,</span> <span class="n">relative_cost</span><span class="p">,</span> <span class="s2">&quot; : &quot;</span><span class="p">,</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">costs</span><span class="p">)])</span>
    

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">3000</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">left</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

<span class="n">rect</span> <span class="o">=</span> <span class="n">Rectangle</span><span class="p">((</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mi">3000</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">rect</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mi">3000</span><span class="p">,</span> <span class="s2">&quot;zoom&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;bottom&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimal thresholds:
relative cost =  20  :  0.007
relative cost =  50  :  0.007
relative cost =  100  :  0.007
</pre></div>
</div>
<img alt="../_images/0e22576439a9ce2c70dbb4d906a3ae7f01d94a88763c8eb30ee5e319adc32b3a.png" src="../_images/0e22576439a9ce2c70dbb4d906a3ae7f01d94a88763c8eb30ee5e319adc32b3a.png" />
</div>
</div>
<div align="center">
<p><strong>Figure - Cost function for different costs of False Negatives (undetected frauds)</strong></p>
<p>Though the cost functions are different, the optimal threshold always ends up right at the tipping point where the recall plateaus and the precision drops.</p>
</div><div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">THRESHOLD</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">Y_proba_platt</span> <span class="o">=</span> <span class="n">model_platt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">predicted_classes</span> <span class="o">=</span> <span class="n">classify</span><span class="p">(</span><span class="n">Y_proba_platt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">THRESHOLD</span><span class="p">)</span>

<span class="n">TPR</span> <span class="o">=</span> <span class="n">compute_TPR</span><span class="p">(</span><span class="n">Y_test</span><span class="o">.</span><span class="n">to_list</span><span class="p">(),</span> <span class="n">predicted_classes</span><span class="p">)</span>
<span class="n">precision</span> <span class="o">=</span> <span class="n">compute_precision</span><span class="p">(</span><span class="n">Y_test</span><span class="o">.</span><span class="n">to_list</span><span class="p">(),</span> <span class="n">predicted_classes</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimal threhsold: &quot;</span><span class="p">,</span> <span class="n">THRESHOLD</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TPR: &quot;</span><span class="p">,</span> <span class="n">TPR</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Precision: &quot;</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>

<span class="c1">#with open(&quot;../models/model_lr_platt.pkl&quot;, &quot;wb&quot;) as f:</span>
<span class="c1">#    pickle.dump(model_platt, f)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimal threhsold:  0.01
TPR:  0.7746478873239436
Precision:  0.5
</pre></div>
</div>
</div>
</div>
</section>
<section id="logistic-regression-conclusion">
<h2>Logistic Regression — Conclusion<a class="headerlink" href="#logistic-regression-conclusion" title="Link to this heading">#</a></h2>
<p>Logistic Regression provides a strong baseline and serves as a useful framework to introduce time-aware splitting, appropriate evaluation metrics for class imbalance, probability calibration, and cost-based threshold selection.</p>
<p>While the resulting ROC and PR performances appear very high, they should be interpreted cautiously given the limited temporal span of the dataset and the risk of learning dataset-specific patterns. This baseline establishes a solid reference point for evaluating a higher-capacity model in the next section.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="01_eda.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Exploratory Data Analysis</p>
      </div>
    </a>
    <a class="right-next"
       href="03_XGB.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Gradient boosted-tree using XGBoost</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-splits">Time Splits</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-evaluation">Model Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calibration">Calibration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limits">Limits</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#threshold-selection">Threshold selection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression-conclusion">Logistic Regression — Conclusion</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Louis Etien
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>